---
title: The hard thing about AI isn't making it, but testing it
layout: post
type: news
permalink: "/ai-development-testing"
categories:
- automated-testing
- software-development
author: Ben Still
tags: []
date: 2018-11-26 13:31:36 +1100
description: AI and Machine Learning are amazing technologies. But in some cases it
  can be hard to know when they are actually working
keywords: ai development, machine learning, automated tests
image-small: "/assets/uploads/2018/extra_large-1498661132-cover-image-1.jpg"
image-large: "/assets/uploads/2018/extra_large-1498661132-cover-image.jpg"
excerpt-short: ''
excerpt-long: ''

---
Before you start pitching to your investors about how amazing the world will be once you get some AI in your product, spare a thought for the engineering team behind Tay, [the Microsoft AI chatbot](https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist). 

> Unfortunately, the conversations didn't stay playful for long. Pretty soon after Tay launched, people starting tweeting the bot with all sorts of misogynistic, racist, and Donald Trumpist remarks. And Tay â€” being essentially a robot parrot with an internet connection â€” started repeating these sentiments back to users

AI technology is amazing, and it's changing and evolving at a rapid pace. It's gone from a hard, obscure technology to a simple service that you can quickly integrate into your product. 

But it can often be quite hard to get a handle on how well it's working. Or if it is actually working at all. In a recent project, we decided to use AI to help us choose a good pet to adopt.

So if you looked at this dog 

# ğŸ•

and liked it, should we show you

# ğŸ© 

or

# ğŸˆ